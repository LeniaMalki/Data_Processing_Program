{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d71ddd3",
   "metadata": {},
   "source": [
    "### Imports necessary to run program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab02ed1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "openTime = datetime.datetime.strptime('9:30:0','%H:%M:%S').time()\n",
    "closeTime = datetime.datetime.strptime('16:0:0','%H:%M:%S').time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86578599",
   "metadata": {},
   "source": [
    "### Converts txt-files to csv-files and filters out data.\n",
    "Note: The directory and output_path must exist in /Data_handler_tradingbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "388dfcff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processData(directory):\n",
    "    print('Processing ' + str(directory)+'...')\n",
    "    for file in os.listdir(directory): \n",
    "        filename = os.fsdecode(file)\n",
    "        print(str(filename) + str('...'))\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        m = filename.split('_')[0]\n",
    "        out = '{}.csv'.format(m) \n",
    "\n",
    "        df =  pd.read_csv(file_path, sep=',', header=None,low_memory=False)\n",
    "        df.columns = [\"DateTime\", \"Open\", \"High\", \"Low\",\"Close\", \"Volume\"]\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "\n",
    "        indecis = []\n",
    "        for i in range(len(df.index)):\n",
    "            given_time = df['DateTime'][i].time()\n",
    "\n",
    "            if not (openTime <= given_time <= closeTime):\n",
    "                indecis.append(i)\n",
    "\n",
    "        df.drop(indecis, axis=0, inplace=True)\n",
    "        print('....... dropped ' +  str(len(indecis)) + ' rows')\n",
    "\n",
    "        output_path = 'temporary_output\\{}'.format(out) \n",
    "        df.to_csv(output_path, index=False)\n",
    "        print('....... created CSV file')\n",
    "    print('DONE PROCESSING DIRECTORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c665dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stockstorun...\n",
      "ABMD_1min.txt...\n",
      "....... dropped 12023 rows\n",
      "....... created CSV file\n",
      "ANET_1min.txt...\n",
      "....... dropped 13269 rows\n",
      "....... created CSV file\n",
      "ANSS_1min.txt...\n",
      "....... dropped 13767 rows\n",
      "....... created CSV file\n",
      "APH_1min.txt...\n",
      "....... dropped 10833 rows\n",
      "....... created CSV file\n",
      "ASH_1min.txt...\n",
      "....... dropped 10527 rows\n",
      "....... created CSV file\n",
      "AXP_1min.txt...\n",
      "....... dropped 80295 rows\n",
      "....... created CSV file\n",
      "A_1min.txt...\n",
      "....... dropped 20784 rows\n",
      "....... created CSV file\n",
      "CBH_1min.txt...\n",
      "....... dropped 250 rows\n",
      "....... created CSV file\n",
      "CINF_1min.txt...\n",
      "....... dropped 21386 rows\n",
      "....... created CSV file\n",
      "CNX_1min.txt...\n",
      "....... dropped 27063 rows\n",
      "....... created CSV file\n",
      "DD_1min.txt...\n",
      "....... dropped 8857 rows\n",
      "....... created CSV file\n",
      "DELL_1min.txt...\n",
      "....... dropped 10506 rows\n",
      "....... created CSV file\n",
      "DISCK_1min.txt...\n",
      "....... dropped 12153 rows\n",
      "....... created CSV file\n",
      "ENPH_1min.txt...\n",
      "....... dropped 40580 rows\n",
      "....... created CSV file\n",
      "ETR_1min.txt...\n",
      "....... dropped 13609 rows\n",
      "....... created CSV file\n",
      "FAST_1min.txt...\n",
      "....... dropped 29791 rows\n",
      "....... created CSV file\n",
      "FE_1min.txt...\n",
      "....... dropped 20220 rows\n",
      "....... created CSV file\n",
      "FRC_1min.txt...\n",
      "....... dropped 6438 rows\n",
      "....... created CSV file\n",
      "FTNT_1min.txt...\n",
      "....... dropped 20182 rows\n",
      "....... created CSV file\n",
      "GWW_1min.txt...\n",
      "....... dropped 9847 rows\n",
      "....... created CSV file\n",
      "HBAN_1min.txt...\n",
      "....... dropped 50001 rows\n",
      "....... created CSV file\n",
      "HII_1min.txt...\n",
      "....... dropped 4105 rows\n",
      "....... created CSV file\n",
      "HST_1min.txt...\n",
      "....... dropped 19595 rows\n",
      "....... created CSV file\n",
      "JD_1min.txt...\n",
      "....... dropped 161847 rows\n",
      "....... created CSV file\n",
      "LOGI_1min.txt...\n",
      "....... dropped 18131 rows\n",
      "....... created CSV file\n",
      "LRCX_1min.txt...\n",
      "....... dropped 55269 rows\n",
      "....... created CSV file\n",
      "NEE_1min.txt...\n",
      "....... dropped 26449 rows\n",
      "....... created CSV file\n",
      "NKTR_1min.txt...\n",
      "....... dropped 24484 rows\n",
      "....... created CSV file\n",
      "NOW_1min.txt...\n",
      "....... dropped 17315 rows\n",
      "....... created CSV file\n",
      "OTIS_1min.txt...\n",
      "....... dropped 2661 rows\n",
      "....... created CSV file\n",
      "PFG_1min.txt...\n",
      "....... dropped 15041 rows\n",
      "....... created CSV file\n",
      "PGR_1min.txt...\n",
      "....... dropped 15652 rows\n",
      "....... created CSV file\n",
      "PSX_1min.txt...\n",
      "....... dropped 22643 rows\n",
      "....... created CSV file\n",
      "REG_1min.txt...\n",
      "....... dropped 11259 rows\n",
      "....... created CSV file\n",
      "SANM_1min.txt...\n",
      "....... dropped 13451 rows\n",
      "....... created CSV file\n",
      "SIVB_1min.txt...\n",
      "....... dropped 14435 rows\n",
      "....... created CSV file\n",
      "SO_1min.txt...\n",
      "....... dropped 27067 rows\n",
      "....... created CSV file\n",
      "TTWO_1min.txt...\n",
      "....... dropped 39272 rows\n",
      "....... created CSV file\n",
      "T_1min.txt...\n",
      "....... dropped 270569 rows\n",
      "....... created CSV file\n",
      "URI_1min.txt...\n",
      "....... dropped 22113 rows\n",
      "....... created CSV file\n",
      "DONE PROCESSING DIRECTORY\n"
     ]
    }
   ],
   "source": [
    "processData('Stockstorun')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea8780",
   "metadata": {},
   "source": [
    "### Data processor for single files\n",
    "Note: the file must be directly accesible from /Data_handler_tradingbot and not in a subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eee0d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'FILE_NAME_IN_STRING' # Name of txt file\n",
    "dat =  pd.read_csv(file, sep=',', header=None,low_memory=False) # dataframe creator \n",
    "dat.columns = [\"DateTime\", \"Open\", \"High\", \"Low\",\"Close\", \"Volume\"] # adding column names \n",
    "dat[\"DateTime\"] = pd.to_datetime(dat[\"DateTime\"]) # assigning type to \"DateTime\"-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945637c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indecis = [] # List of indecis to be removed \n",
    "\n",
    "for i in range(len(dat.index)): # Iterate thourgh the file\n",
    "    given_time = dat['DateTime'][i].time() # Get the time of index i \n",
    "    \n",
    "    if not (openTime <= given_time <= closeTime): # if the time is not within the market... \n",
    "        indecis.append(i) # save its index \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cc09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat.drop(indecis, axis=0, inplace=True) # drop/remove all rows correcponding to indecis of the list of indecis\n",
    "print('Dropped: ' +  str(len(indecis)) + ' rows')\n",
    "\n",
    "output_path = 'temporary_output\\{}.csv'.format('OUTPUT_NAME_IN_STRING') # specify the output-path \n",
    "dat.to_csv(output_path, index=False) # convert tha dataframe to csv and save it to the specified output-path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aab65f",
   "metadata": {},
   "source": [
    "### Name handeling if file names need to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'DIRECTORY_NAME_IN_STRING'\n",
    "for file in os.listdir(directory): \n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    f_name, f_ext = os.path.splitext(file)\n",
    "    new_name = filename.replace(\".txt\",\"\")\n",
    "    \n",
    "    file_path = os.path.join(directory, filename)\n",
    "    new_file = os.path.join(directory, new_name)\n",
    "        \n",
    "    os.rename(file_path, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa75485",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb93040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'stockstorun.txt' # Name of txt file\n",
    "dat =  pd.read_csv(file, sep=',', header=None,low_memory=False) # dataframe creator \n",
    "dat.columns = [\"Ticker\"] # adding column names \n",
    "dat.sort_values(by=['Ticker'], inplace=True, ignore_index=True)\n",
    "display(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_frame = pd.DataFrame()\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir('Stockstorun'): \n",
    "        filename = os.fsdecode(file)\n",
    "        file_path = os.path.join('Stockstorun', filename)\n",
    "        dataframe =  pd.read_csv(file_path, sep=',')\n",
    "        dfs.append(dataframe)\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8f9367c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>A</th>\n",
       "      <th>DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-03 09:30:00</td>\n",
       "      <td>65.9370</td>\n",
       "      <td>62.3751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-03 09:31:00</td>\n",
       "      <td>66.2551</td>\n",
       "      <td>62.4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03 09:32:00</td>\n",
       "      <td>66.0740</td>\n",
       "      <td>62.4463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-03 09:33:00</td>\n",
       "      <td>66.0642</td>\n",
       "      <td>62.2896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-03 09:34:00</td>\n",
       "      <td>66.3285</td>\n",
       "      <td>62.3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273981</th>\n",
       "      <td>2022-04-08 15:55:00</td>\n",
       "      <td>134.7460</td>\n",
       "      <td>68.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273982</th>\n",
       "      <td>2022-04-08 15:56:00</td>\n",
       "      <td>134.7850</td>\n",
       "      <td>68.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273983</th>\n",
       "      <td>2022-04-08 15:57:00</td>\n",
       "      <td>134.7100</td>\n",
       "      <td>68.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273984</th>\n",
       "      <td>2022-04-08 15:58:00</td>\n",
       "      <td>134.7800</td>\n",
       "      <td>68.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273985</th>\n",
       "      <td>2022-04-08 15:59:00</td>\n",
       "      <td>134.9900</td>\n",
       "      <td>68.8700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DateTime         A       DD\n",
       "0       2019-06-03 09:30:00   65.9370  62.3751\n",
       "1       2019-06-03 09:31:00   66.2551  62.4036\n",
       "2       2019-06-03 09:32:00   66.0740  62.4463\n",
       "3       2019-06-03 09:33:00   66.0642  62.2896\n",
       "4       2019-06-03 09:34:00   66.3285  62.3561\n",
       "...                     ...       ...      ...\n",
       "273981  2022-04-08 15:55:00  134.7460  68.7800\n",
       "273982  2022-04-08 15:56:00  134.7850  68.7200\n",
       "273983  2022-04-08 15:57:00  134.7100  68.6700\n",
       "273984  2022-04-08 15:58:00  134.7800  68.7000\n",
       "273985  2022-04-08 15:59:00  134.9900  68.8700\n",
       "\n",
       "[273986 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path1 = os.path.join('temporary_output', os.fsdecode('A.csv'))\n",
    "df1 = pd.read_csv(file_path1, sep=',')[['DateTime', 'Close']]\n",
    "df1.columns = ['DateTime','A']\n",
    "\n",
    "file_path2 = os.path.join('temporary_output', os.fsdecode('DD.csv'))\n",
    "df2 = pd.read_csv(file_path2, sep=',')[['DateTime', 'Close']]\n",
    "df2.columns = ['DateTime','DD']\n",
    "\n",
    "df = pd.merge(df1, df2, on=['DateTime'])\n",
    "display(df)\n",
    "\n",
    "#df.to_csv('nyy.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "967b36cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-03 09:30:00</td>\n",
       "      <td>15.7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03 09:31:00</td>\n",
       "      <td>15.6958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03 09:32:00</td>\n",
       "      <td>15.7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-03 09:33:00</td>\n",
       "      <td>15.7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-03 09:34:00</td>\n",
       "      <td>15.7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670871</th>\n",
       "      <td>2022-04-08 15:55:00</td>\n",
       "      <td>134.7460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670872</th>\n",
       "      <td>2022-04-08 15:56:00</td>\n",
       "      <td>134.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670873</th>\n",
       "      <td>2022-04-08 15:57:00</td>\n",
       "      <td>134.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670874</th>\n",
       "      <td>2022-04-08 15:58:00</td>\n",
       "      <td>134.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670875</th>\n",
       "      <td>2022-04-08 15:59:00</td>\n",
       "      <td>134.9900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1670876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DateTime         A\n",
       "0        2005-01-03 09:30:00   15.7088\n",
       "1        2005-01-03 09:31:00   15.6958\n",
       "2        2005-01-03 09:32:00   15.7023\n",
       "3        2005-01-03 09:33:00   15.7088\n",
       "4        2005-01-03 09:34:00   15.7023\n",
       "...                      ...       ...\n",
       "1670871  2022-04-08 15:55:00  134.7460\n",
       "1670872  2022-04-08 15:56:00  134.7850\n",
       "1670873  2022-04-08 15:57:00  134.7100\n",
       "1670874  2022-04-08 15:58:00  134.7800\n",
       "1670875  2022-04-08 15:59:00  134.9900\n",
       "\n",
       "[1670876 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_path = os.path.join('temporary_output', 'A.csv')\n",
    "first_df = pd.read_csv(first_path, sep=',')[['DateTime', 'Close']]\n",
    "first_df.columns = ['DateTime','A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1c407505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    DateTime     Close\n",
      "0        2005-01-03 09:30:00   15.7088\n",
      "1        2005-01-03 09:31:00   15.6958\n",
      "2        2005-01-03 09:32:00   15.7023\n",
      "3        2005-01-03 09:33:00   15.7088\n",
      "4        2005-01-03 09:34:00   15.7023\n",
      "...                      ...       ...\n",
      "1670871  2022-04-08 15:55:00  134.7460\n",
      "1670872  2022-04-08 15:56:00  134.7850\n",
      "1670873  2022-04-08 15:57:00  134.7100\n",
      "1670874  2022-04-08 15:58:00  134.7800\n",
      "1670875  2022-04-08 15:59:00  134.9900\n",
      "\n",
      "[1670876 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_dataframe = pd.read_csv('A.csv', sep=',')[['DateTime', 'Close']]\n",
    "print(csv_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ab87a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>A</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ANET</th>\n",
       "      <th>ANSS</th>\n",
       "      <th>APH</th>\n",
       "      <th>ASH</th>\n",
       "      <th>AXP</th>\n",
       "      <th>CBH</th>\n",
       "      <th>CINF</th>\n",
       "      <th>...</th>\n",
       "      <th>PFG</th>\n",
       "      <th>PGR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>REG</th>\n",
       "      <th>SANM</th>\n",
       "      <th>SIVB</th>\n",
       "      <th>SO</th>\n",
       "      <th>T</th>\n",
       "      <th>TTWO</th>\n",
       "      <th>URI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-19 13:56:00</td>\n",
       "      <td>65.7436</td>\n",
       "      <td>139.940</td>\n",
       "      <td>45.9875</td>\n",
       "      <td>219.275</td>\n",
       "      <td>33.6956</td>\n",
       "      <td>43.8751</td>\n",
       "      <td>72.1325</td>\n",
       "      <td>5.8978</td>\n",
       "      <td>79.5350</td>\n",
       "      <td>...</td>\n",
       "      <td>25.4438</td>\n",
       "      <td>63.1182</td>\n",
       "      <td>39.2111</td>\n",
       "      <td>35.9514</td>\n",
       "      <td>21.430</td>\n",
       "      <td>173.440</td>\n",
       "      <td>48.0183</td>\n",
       "      <td>27.2350</td>\n",
       "      <td>107.750</td>\n",
       "      <td>73.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-19 13:59:00</td>\n",
       "      <td>64.7979</td>\n",
       "      <td>138.050</td>\n",
       "      <td>45.8470</td>\n",
       "      <td>218.585</td>\n",
       "      <td>33.5778</td>\n",
       "      <td>43.8361</td>\n",
       "      <td>71.7874</td>\n",
       "      <td>5.8807</td>\n",
       "      <td>79.0747</td>\n",
       "      <td>...</td>\n",
       "      <td>25.2602</td>\n",
       "      <td>62.8760</td>\n",
       "      <td>39.1196</td>\n",
       "      <td>35.7851</td>\n",
       "      <td>21.335</td>\n",
       "      <td>171.280</td>\n",
       "      <td>47.8897</td>\n",
       "      <td>27.1571</td>\n",
       "      <td>108.180</td>\n",
       "      <td>73.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-19 15:08:00</td>\n",
       "      <td>64.2068</td>\n",
       "      <td>138.850</td>\n",
       "      <td>45.5102</td>\n",
       "      <td>223.555</td>\n",
       "      <td>33.4649</td>\n",
       "      <td>43.8021</td>\n",
       "      <td>73.0185</td>\n",
       "      <td>6.3185</td>\n",
       "      <td>79.3594</td>\n",
       "      <td>...</td>\n",
       "      <td>24.7137</td>\n",
       "      <td>62.2426</td>\n",
       "      <td>39.5371</td>\n",
       "      <td>35.4341</td>\n",
       "      <td>22.140</td>\n",
       "      <td>168.915</td>\n",
       "      <td>47.3799</td>\n",
       "      <td>26.7894</td>\n",
       "      <td>107.820</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-23 14:43:00</td>\n",
       "      <td>62.8179</td>\n",
       "      <td>131.420</td>\n",
       "      <td>40.2875</td>\n",
       "      <td>211.850</td>\n",
       "      <td>34.4514</td>\n",
       "      <td>39.0238</td>\n",
       "      <td>67.3693</td>\n",
       "      <td>5.3741</td>\n",
       "      <td>66.8590</td>\n",
       "      <td>...</td>\n",
       "      <td>22.4774</td>\n",
       "      <td>62.7363</td>\n",
       "      <td>38.1443</td>\n",
       "      <td>31.5591</td>\n",
       "      <td>22.380</td>\n",
       "      <td>150.345</td>\n",
       "      <td>39.8622</td>\n",
       "      <td>23.0001</td>\n",
       "      <td>110.500</td>\n",
       "      <td>71.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-24 11:14:00</td>\n",
       "      <td>66.4873</td>\n",
       "      <td>141.685</td>\n",
       "      <td>44.6975</td>\n",
       "      <td>214.490</td>\n",
       "      <td>35.3593</td>\n",
       "      <td>41.5443</td>\n",
       "      <td>75.9167</td>\n",
       "      <td>6.0180</td>\n",
       "      <td>70.9593</td>\n",
       "      <td>...</td>\n",
       "      <td>25.2188</td>\n",
       "      <td>64.0637</td>\n",
       "      <td>40.0261</td>\n",
       "      <td>35.1570</td>\n",
       "      <td>24.270</td>\n",
       "      <td>152.670</td>\n",
       "      <td>42.7462</td>\n",
       "      <td>23.6359</td>\n",
       "      <td>111.020</td>\n",
       "      <td>83.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>2022-04-08 14:45:00</td>\n",
       "      <td>135.4950</td>\n",
       "      <td>316.005</td>\n",
       "      <td>131.4900</td>\n",
       "      <td>305.050</td>\n",
       "      <td>73.4100</td>\n",
       "      <td>100.0400</td>\n",
       "      <td>183.9100</td>\n",
       "      <td>9.2300</td>\n",
       "      <td>137.3100</td>\n",
       "      <td>...</td>\n",
       "      <td>73.7300</td>\n",
       "      <td>118.3000</td>\n",
       "      <td>84.1500</td>\n",
       "      <td>70.3200</td>\n",
       "      <td>38.570</td>\n",
       "      <td>501.635</td>\n",
       "      <td>76.5900</td>\n",
       "      <td>24.1071</td>\n",
       "      <td>141.220</td>\n",
       "      <td>317.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>2022-04-08 15:28:00</td>\n",
       "      <td>135.4300</td>\n",
       "      <td>317.150</td>\n",
       "      <td>131.6900</td>\n",
       "      <td>305.140</td>\n",
       "      <td>73.6000</td>\n",
       "      <td>100.1600</td>\n",
       "      <td>184.1900</td>\n",
       "      <td>9.2200</td>\n",
       "      <td>137.7800</td>\n",
       "      <td>...</td>\n",
       "      <td>73.9250</td>\n",
       "      <td>118.3500</td>\n",
       "      <td>84.4900</td>\n",
       "      <td>70.5500</td>\n",
       "      <td>38.670</td>\n",
       "      <td>505.080</td>\n",
       "      <td>76.6500</td>\n",
       "      <td>24.1450</td>\n",
       "      <td>141.720</td>\n",
       "      <td>318.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>2022-04-08 15:38:00</td>\n",
       "      <td>135.1200</td>\n",
       "      <td>316.810</td>\n",
       "      <td>131.0950</td>\n",
       "      <td>304.750</td>\n",
       "      <td>73.5150</td>\n",
       "      <td>99.8100</td>\n",
       "      <td>183.8500</td>\n",
       "      <td>9.2200</td>\n",
       "      <td>137.9400</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8400</td>\n",
       "      <td>118.4050</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>70.5700</td>\n",
       "      <td>38.600</td>\n",
       "      <td>503.830</td>\n",
       "      <td>76.6050</td>\n",
       "      <td>24.1350</td>\n",
       "      <td>141.545</td>\n",
       "      <td>317.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>2022-04-08 15:57:00</td>\n",
       "      <td>134.7100</td>\n",
       "      <td>314.325</td>\n",
       "      <td>130.9000</td>\n",
       "      <td>303.010</td>\n",
       "      <td>73.1700</td>\n",
       "      <td>99.4100</td>\n",
       "      <td>183.4250</td>\n",
       "      <td>9.2500</td>\n",
       "      <td>137.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.4900</td>\n",
       "      <td>118.2300</td>\n",
       "      <td>84.1350</td>\n",
       "      <td>70.4900</td>\n",
       "      <td>38.350</td>\n",
       "      <td>500.500</td>\n",
       "      <td>76.4050</td>\n",
       "      <td>24.1300</td>\n",
       "      <td>141.335</td>\n",
       "      <td>316.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>2022-04-08 15:59:00</td>\n",
       "      <td>134.9900</td>\n",
       "      <td>313.980</td>\n",
       "      <td>131.0400</td>\n",
       "      <td>303.010</td>\n",
       "      <td>73.3000</td>\n",
       "      <td>99.4700</td>\n",
       "      <td>183.7100</td>\n",
       "      <td>9.2500</td>\n",
       "      <td>137.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>73.6100</td>\n",
       "      <td>118.5000</td>\n",
       "      <td>84.2900</td>\n",
       "      <td>70.5200</td>\n",
       "      <td>38.380</td>\n",
       "      <td>500.370</td>\n",
       "      <td>76.5200</td>\n",
       "      <td>24.1400</td>\n",
       "      <td>141.300</td>\n",
       "      <td>317.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3061 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DateTime         A     ABMD      ANET     ANSS      APH  \\\n",
       "0     2020-03-19 13:56:00   65.7436  139.940   45.9875  219.275  33.6956   \n",
       "1     2020-03-19 13:59:00   64.7979  138.050   45.8470  218.585  33.5778   \n",
       "2     2020-03-19 15:08:00   64.2068  138.850   45.5102  223.555  33.4649   \n",
       "3     2020-03-23 14:43:00   62.8179  131.420   40.2875  211.850  34.4514   \n",
       "4     2020-03-24 11:14:00   66.4873  141.685   44.6975  214.490  35.3593   \n",
       "...                   ...       ...      ...       ...      ...      ...   \n",
       "3056  2022-04-08 14:45:00  135.4950  316.005  131.4900  305.050  73.4100   \n",
       "3057  2022-04-08 15:28:00  135.4300  317.150  131.6900  305.140  73.6000   \n",
       "3058  2022-04-08 15:38:00  135.1200  316.810  131.0950  304.750  73.5150   \n",
       "3059  2022-04-08 15:57:00  134.7100  314.325  130.9000  303.010  73.1700   \n",
       "3060  2022-04-08 15:59:00  134.9900  313.980  131.0400  303.010  73.3000   \n",
       "\n",
       "           ASH       AXP     CBH      CINF  ...      PFG       PGR      PSX  \\\n",
       "0      43.8751   72.1325  5.8978   79.5350  ...  25.4438   63.1182  39.2111   \n",
       "1      43.8361   71.7874  5.8807   79.0747  ...  25.2602   62.8760  39.1196   \n",
       "2      43.8021   73.0185  6.3185   79.3594  ...  24.7137   62.2426  39.5371   \n",
       "3      39.0238   67.3693  5.3741   66.8590  ...  22.4774   62.7363  38.1443   \n",
       "4      41.5443   75.9167  6.0180   70.9593  ...  25.2188   64.0637  40.0261   \n",
       "...        ...       ...     ...       ...  ...      ...       ...      ...   \n",
       "3056  100.0400  183.9100  9.2300  137.3100  ...  73.7300  118.3000  84.1500   \n",
       "3057  100.1600  184.1900  9.2200  137.7800  ...  73.9250  118.3500  84.4900   \n",
       "3058   99.8100  183.8500  9.2200  137.9400  ...  73.8400  118.4050  84.2500   \n",
       "3059   99.4100  183.4250  9.2500  137.8000  ...  73.4900  118.2300  84.1350   \n",
       "3060   99.4700  183.7100  9.2500  137.8100  ...  73.6100  118.5000  84.2900   \n",
       "\n",
       "          REG    SANM     SIVB       SO        T     TTWO     URI  \n",
       "0     35.9514  21.430  173.440  48.0183  27.2350  107.750   73.14  \n",
       "1     35.7851  21.335  171.280  47.8897  27.1571  108.180   73.31  \n",
       "2     35.4341  22.140  168.915  47.3799  26.7894  107.820   77.00  \n",
       "3     31.5591  22.380  150.345  39.8622  23.0001  110.500   71.42  \n",
       "4     35.1570  24.270  152.670  42.7462  23.6359  111.020   83.35  \n",
       "...       ...     ...      ...      ...      ...      ...     ...  \n",
       "3056  70.3200  38.570  501.635  76.5900  24.1071  141.220  317.08  \n",
       "3057  70.5500  38.670  505.080  76.6500  24.1450  141.720  318.41  \n",
       "3058  70.5700  38.600  503.830  76.6050  24.1350  141.545  317.70  \n",
       "3059  70.4900  38.350  500.500  76.4050  24.1300  141.335  316.76  \n",
       "3060  70.5200  38.380  500.370  76.5200  24.1400  141.300  317.30  \n",
       "\n",
       "[3061 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_dataframe = pd.read_csv('A.csv', sep=',')[['DateTime', 'Close']]\n",
    "csv_dataframe.columns = ['DateTime','A']\n",
    "\n",
    "for file in os.listdir('temporary_output'): \n",
    "    global csv_dataframe\n",
    "    \n",
    "    path = os.path.join('temporary_output', file)\n",
    "    ticker = file.replace(\".csv\",\"\")\n",
    "    temp_df = pd.read_csv(path, sep=',')[['DateTime', 'Close']]\n",
    "    temp_df.columns = ['DateTime',ticker]\n",
    "\n",
    "    csv_dataframe = pd.merge(csv_dataframe, temp_df, on=['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7fe1ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataframe.sort_values(by=['DateTime'], inplace=True, ignore_index=True)\n",
    "csv_dataframe.to_csv('final.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
